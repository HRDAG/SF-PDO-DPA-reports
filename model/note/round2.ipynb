{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2ab45a-54a1-46aa-ba6a-0c7009321a5a",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\\\n",
    "From TS:\n",
    "> \"This is a great start! I'd love to see the distribution of outcomes being predicted. Specifically **wondering how unbalanced the labels are (basically how rare are sustained findings)**, to think about sampling in such a way to **oversample the sustained findings for the train split**. And of course **more fine-grained features**, currently we have a single T/F for any of a collection of keywords expected to be relevant, but perhaps (1) distinct features for different keywords/phrases, or (2) denser topic models or (3) other embeddings. Just a thought.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a1da1e-87f0-475c-ba40-58e3a259301f",
   "metadata": {},
   "source": [
    "Next to explore\n",
    "\n",
    "> (2) denser topic models\n",
    ">\n",
    "> (3) other embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfbb69-4d04-4cae-80b9-3cb4c7afa309",
   "metadata": {},
   "source": [
    "# setup - general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fded80a7-f04a-4d00-8db3-72609229d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa17b6f7-ffb2-483d-9765-119348df5d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support methods\n",
    "def group_finding(x):\n",
    "    if x.sustained | x.mediated: return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def combine_indicators(x):\n",
    "    true = sorted([c for c in top_inds if x[c] == True])\n",
    "    if not any(true): return 'other_factor(s)'\n",
    "    return \"|\".join(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "311603fa-09cb-4377-bcb4-94d9af0f2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "raw = pd.read_parquet(\"../../export/output/complaints.parquet\")\n",
    "\n",
    "basecols = ['allegation_id', 'allegations', 'finding',]\n",
    "# metadata about the complaint/allegation\n",
    "meta = ['report_type', 'dpa_added', 'occ_added']\n",
    "# phrases that suggest something about the investigation into the allegation\n",
    "proc = ['no_officer_id', 'default_finding', 'withdrawn', 'jlp', 'bwc', 'mediated']\n",
    "# potentials values for use of force allegation: CA P.C. 835, SFPD G.O. 5.01\n",
    "kw_g1 = ['intimidation', 'racial_bias', 'resisting', 'force', 'pursuit', 'swat', 'firearm', 'taser', 'crisis']\n",
    "kw_g2 = ['home', 'minor',]\n",
    "raw['uof_kw'] = raw[kw_g1].apply(lambda x: any(x.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc52206-8fd8-42cf-a7fa-bb111f123404",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['eligible'] = ~(raw.dpa_added | raw.occ_added | raw.withdrawn)\n",
    "raw['sus_or_med'] = raw.apply(group_finding, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414984e-f94e-4a52-a227-8b35676d334d",
   "metadata": {},
   "source": [
    "# data subset options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4a0aaa-2e93-4fa0-ba6c-0a01c087da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'category_of_conduct',\n",
    "    'finding'\n",
    "]\n",
    "base_ind = [c for c in raw.columns if 'wo_cause' in c]\n",
    "indicators = base_ind + [\n",
    "    'bias',\n",
    "    'bwc',\n",
    "    'crisis',\n",
    "    'dishonesty',\n",
    "    'failed_reqmt',\n",
    "    'firearm',\n",
    "    'force',\n",
    "    'inapp_action',\n",
    "    'jlp',\n",
    "    'malignant_action',\n",
    "    'minor',\n",
    "    'pursuit',\n",
    "    'racial_bias',\n",
    "    'resisting',\n",
    "    'sus_or_med',\n",
    "    'unnec_force',\n",
    "]\n",
    "includecols = ['allegation_id',] + categories + indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc7cd24-6397-4781-ab60-776fb55eb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the data with mostly-cleaned allegations\n",
    "dpa = raw.loc[raw.eligible, includecols].drop_duplicates().dropna()\n",
    "picky = raw.loc[(\n",
    "    raw.eligible) & (\n",
    "    raw.finding.isin(raw.finding.value_counts().head(5).index)),\n",
    "    includecols].sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f3c00a-a06c-449d-be55-be51ad7a82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_inds = [\n",
    "    col for col,highprop in (\n",
    "    dpa[indicators].sum() > 3000).to_dict().items()\n",
    "    if highprop]\n",
    "focuscols = ['allegation_id', 'sus_or_med'] + top_inds\n",
    "dpa['factor_group'] = dpa[top_inds].apply(\n",
    "    lambda x: combine_indicators(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0bbfa4-3e1c-4f0f-a13f-143fafccf58c",
   "metadata": {},
   "source": [
    "# setup - model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eda45e9-180d-4e3e-82c4-8838ef50b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "npos = dpa.sus_or_med.sum()\n",
    "pos = dpa.loc[dpa.sus_or_med, focuscols]\n",
    "neg = dpa.loc[~(dpa.sus_or_med), focuscols].sample(npos)\n",
    "truesplit = pd.concat([pos, neg])\n",
    "\n",
    "train, test = train_test_split(\n",
    "    truesplit,\n",
    "    test_size=.4, train_size=.6,\n",
    "    random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f47d8450-6180-49c2-8440-d2f0476dea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "x_train = train[top_inds].to_numpy()\n",
    "y_train = train.sus_or_med.values.reshape(-1, 1)\n",
    "x_test = test[top_inds].to_numpy()\n",
    "y_test = test.sus_or_med.values.reshape(-1, 1)\n",
    "\n",
    "model.fit(X=x_train, y=np.ravel(y_train,order=\"c\"))\n",
    "\n",
    "test['predicted_finding'] = model.predict(X=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04841296-128c-4340-a4b5-fcaba01b19f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6247113163972287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.43      0.53       858\n",
      "        True       0.59      0.81      0.69       874\n",
      "\n",
      "    accuracy                           0.62      1732\n",
      "   macro avg       0.64      0.62      0.61      1732\n",
      "weighted avg       0.64      0.62      0.61      1732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, test.predicted_finding))\n",
    "print(classification_report(y_test, test.predicted_finding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da468abf-8e65-4e9e-a0cb-1157a9740468",
   "metadata": {},
   "source": [
    "# Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f947e65f-6a73-4528-ae65-ba7caf97380e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23327"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c18d40cf-3ce7-4b97-bed6-2f3009a956dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picky.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb135e25-813a-46d1-a839-b75182b0b828",
   "metadata": {},
   "source": [
    "> **wondering how unbalanced the labels are (basically how rare are sustained findings)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaa163d2-fc6e-42c8-b2df-614950f41c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sus_or_med\n",
       "False    0.907232\n",
       "True     0.092768\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa.sus_or_med.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1784b-1fc4-45eb-b8e9-5affa2aef4f2",
   "metadata": {},
   "source": [
    "> think about sampling in such a way to **oversample the sustained findings for the train split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "253bae0e-45ea-4c09-9061-8ed628dc7be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sus_or_med\n",
       "True     0.5\n",
       "False    0.5\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truesplit.sus_or_med.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7dcbb71-f291-44f1-94b2-adac988ad6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sus_or_med\n",
       "False    0.503082\n",
       "True     0.496918\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sus_or_med.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda6d13-303b-4927-9f6c-ff1279286759",
   "metadata": {},
   "source": [
    "> **more fine-grained features**, currently we have a single T/F for any of a collection of keywords expected to be relevant, but perhaps (1) distinct features for different keywords/phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6772ea5b-41d4-498f-b0cd-fae91b02d1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failed_reqmt             6292\n",
       "action_wo_cause          6090\n",
       "inapp_action             5843\n",
       "bwc                      3269\n",
       "force                    3236\n",
       "jlp                      3101\n",
       "sus_or_med               2164\n",
       "unnec_force              1989\n",
       "detain_wo_cause          1950\n",
       "malignant_action         1241\n",
       "arrest_wo_cause          1171\n",
       "cite_wo_cause            1073\n",
       "firearm                   924\n",
       "search_wo_cause           898\n",
       "bias                      716\n",
       "racial_bias               520\n",
       "resisting                 392\n",
       "minor                     385\n",
       "entry_wo_cause            362\n",
       "towed_wo_cause            236\n",
       "dishonesty                230\n",
       "tookproperty_wo_cause     187\n",
       "pursuit                   142\n",
       "crisis                     26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa[indicators].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0baeb521-7072-4230-882c-759c90953a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failed_reqmt       6292\n",
       "action_wo_cause    6090\n",
       "inapp_action       5843\n",
       "bwc                3269\n",
       "force              3236\n",
       "jlp                3101\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa[top_inds].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c311a9-9cf1-4863-adef-be176a5f33f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action_wo_cause  bwc    failed_reqmt  force  inapp_action  jlp  \n",
       "False            False  False         False  True          False    4629\n",
       "True             False  False         False  False         False    4578\n",
       "False            False  True          False  False         False    4381\n",
       "                        False         False  False         False    2463\n",
       "                                      True   False         False    1811\n",
       "True             False  False         False  False         True      661\n",
       "False            True   False         False  True          False     502\n",
       "                 False  True          False  False         True      498\n",
       "                 True   True          False  False         True      472\n",
       "                                                           False     465\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa[top_inds].value_counts().head(10)#.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd981202-8ec3-4d68-a69f-0e7b29cfa037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15395</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>allegation_id</th>\n",
       "      <td>890d6e351425b85b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sus_or_med</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action_wo_cause</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bwc</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed_reqmt</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inapp_action</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jlp</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            15395\n",
       "allegation_id    890d6e351425b85b\n",
       "sus_or_med                  False\n",
       "action_wo_cause             False\n",
       "bwc                         False\n",
       "failed_reqmt                False\n",
       "force                        True\n",
       "inapp_action                False\n",
       "jlp                         False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa[focuscols].sample().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719c1e5-c4e0-4572-a84f-9d138e611d74",
   "metadata": {},
   "source": [
    "\\\n",
    "**BP says:**\n",
    "- I'm wondering if the `sustained` indicator is being calculated accurately\n",
    "- This looks like the thing I might've broken / not fixed last time related to the `findings` regrouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d702f631-9b16-48fe-aae8-70df1b0b68fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sustained  sus_or_med  finding                     \n",
       "False      False       NS                              10071\n",
       "                       Proper Conduct                   6338\n",
       "                       NF                               2363\n",
       "                       Unfounded                        2320\n",
       "True       True        Sustained                        1143\n",
       "False      True        Mediated                         1041\n",
       "           False       NF/W                              883\n",
       "                       Insufficient Evidence             647\n",
       "                       Improper Conduct (Sustained)      210\n",
       "True       True        Policy Failure                    171\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[['sustained', 'sus_or_med', 'finding']].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaaf60a-ad5c-4c24-af80-67609ccd38be",
   "metadata": {},
   "source": [
    "# Review predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a30ce0b-6621-42fb-ac42-ac2778a36652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_finding\n",
       "True     0.692841\n",
       "False    0.307159\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.predicted_finding.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6da0aab-7222-4e01-a403-b2078965bf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sus_or_med  predicted_finding\n",
       "True        True                 712\n",
       "False       True                 488\n",
       "            False                370\n",
       "True        False                162\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['sus_or_med', 'predicted_finding']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1058990d-27ad-406b-a941-08ddaa4376f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "truepos =  test.loc[(test.sus_or_med) & (test.predicted_finding)]\n",
    "falsepos = test.loc[~(test.sus_or_med) & (test.predicted_finding)]\n",
    "trueneg =  test.loc[~(test.sus_or_med | test.predicted_finding)]\n",
    "falseneg = test.loc[(test.sus_or_med) & ~(test.predicted_finding)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486b345-965f-4f64-acdb-01cd9e10f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "truepos.shape[0], falsepos.shape[0], trueneg.shape[0], falseneg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e6153f1-0e80-4b5b-9868-9bf9de87d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "truepos_n = truepos[top_inds].sum(\n",
    "    ).to_frame().rename(columns={0: 'n_truepos'}).T\n",
    "truepos_perc = truepos[top_inds].sum().apply(\n",
    "    lambda x: f\"{x/truepos.shape[0]*100:.1f}%\"\n",
    "    ).to_frame().rename(columns={0: 'perc_truepos'}).T\n",
    "trueneg_n = trueneg[top_inds].sum(\n",
    "    ).to_frame().rename(columns={0: 'n_trueneg'}).T\n",
    "trueneg_perc = trueneg[top_inds].sum().apply(\n",
    "    lambda x: f\"{x/trueneg.shape[0]*100:.1f}%\"\n",
    "    ).to_frame().rename(columns={0: 'perc_trueneg'}).T\n",
    "falsepos_n = falsepos[top_inds].sum(\n",
    "    ).to_frame().rename(columns={0: 'n_falsepos'}).T\n",
    "falsepos_perc = falsepos[top_inds].sum().apply(\n",
    "    lambda x: f\"{x/falsepos.shape[0]*100:.1f}%\"\n",
    "    ).to_frame().rename(columns={0: 'perc_falsepos'}).T\n",
    "falseneg_n = falseneg[top_inds].sum(\n",
    "    ).to_frame().rename(columns={0: 'n_falseneg'}).T\n",
    "falseneg_perc = falseneg[top_inds].sum().apply(\n",
    "    lambda x: f\"{x/falseneg.shape[0]*100:.1f}%\"\n",
    "    ).to_frame().rename(columns={0: 'perc_falseneg'}).T\n",
    "results = pd.concat([\n",
    "    truepos_n, truepos_perc,\n",
    "    trueneg_n, trueneg_perc,\n",
    "    falsepos_n, falsepos_perc,\n",
    "    falseneg_n, falseneg_perc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75ca6cc9-628d-4d07-baa7-ec40084483a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_truepos</th>\n",
       "      <th>perc_truepos</th>\n",
       "      <th>n_trueneg</th>\n",
       "      <th>perc_trueneg</th>\n",
       "      <th>n_falsepos</th>\n",
       "      <th>perc_falsepos</th>\n",
       "      <th>n_falseneg</th>\n",
       "      <th>perc_falseneg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>failed_reqmt</th>\n",
       "      <td>325</td>\n",
       "      <td>45.6%</td>\n",
       "      <td>71</td>\n",
       "      <td>19.2%</td>\n",
       "      <td>146</td>\n",
       "      <td>29.9%</td>\n",
       "      <td>17</td>\n",
       "      <td>10.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inapp_action</th>\n",
       "      <td>225</td>\n",
       "      <td>31.6%</td>\n",
       "      <td>57</td>\n",
       "      <td>15.4%</td>\n",
       "      <td>161</td>\n",
       "      <td>33.0%</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action_wo_cause</th>\n",
       "      <td>164</td>\n",
       "      <td>23.0%</td>\n",
       "      <td>54</td>\n",
       "      <td>14.6%</td>\n",
       "      <td>181</td>\n",
       "      <td>37.1%</td>\n",
       "      <td>9</td>\n",
       "      <td>5.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>46</td>\n",
       "      <td>6.5%</td>\n",
       "      <td>106</td>\n",
       "      <td>28.6%</td>\n",
       "      <td>16</td>\n",
       "      <td>3.3%</td>\n",
       "      <td>49</td>\n",
       "      <td>30.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bwc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>140</td>\n",
       "      <td>37.8%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>46</td>\n",
       "      <td>28.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jlp</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>143</td>\n",
       "      <td>38.6%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                n_truepos perc_truepos n_trueneg perc_trueneg n_falsepos  \\\n",
       "failed_reqmt          325        45.6%        71        19.2%        146   \n",
       "inapp_action          225        31.6%        57        15.4%        161   \n",
       "action_wo_cause       164        23.0%        54        14.6%        181   \n",
       "force                  46         6.5%       106        28.6%         16   \n",
       "bwc                     0         0.0%       140        37.8%          0   \n",
       "jlp                     0         0.0%       143        38.6%          0   \n",
       "\n",
       "                perc_falsepos n_falseneg perc_falseneg  \n",
       "failed_reqmt            29.9%         17         10.5%  \n",
       "inapp_action            33.0%         13          8.0%  \n",
       "action_wo_cause         37.1%          9          5.6%  \n",
       "force                    3.3%         49         30.2%  \n",
       "bwc                      0.0%         46         28.4%  \n",
       "jlp                      0.0%          0          0.0%  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.T.sort_values('n_truepos', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c23b1663-c647-47fa-b46f-4bb0709166fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action_wo_cause    164\n",
       "bwc                  0\n",
       "failed_reqmt       325\n",
       "force               46\n",
       "inapp_action       225\n",
       "jlp                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truepos[top_inds].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801440a-1205-4138-9b53-a2938459b8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
