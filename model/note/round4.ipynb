{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728a5ead-9790-43f3-b730-0c10ee1a5a66",
   "metadata": {},
   "source": [
    "# goals\n",
    "\\\n",
    "From our discussion with Zac, the classifier results could be very useful to the public defenders' team who writes the complaints processed by the DPA, so we should keep working on it.\n",
    "\n",
    "Specifically, any information about what types of allegations get sustained more often or what was recovered in the DPA's investigation that contributed to an allegation becoming a \"positive\" example could help them write complaints that make it clear and actionable for the DPA.\n",
    "\n",
    "To summarize,\n",
    "- allegations that are found to be one of the following are considered \"positive\" examples for the purpose of training the model:\n",
    "    - sustained\n",
    "    - mediated\n",
    "    - deemed to be some kind of policy, training, etc. failure\n",
    "    - anything else?\n",
    "- indicators may be based on two areas of the DPA reports\n",
    "    - \"summary of allegation\": the brief, high-level summary of each individual allegation brought in the complaint\n",
    "    - \"findings of fact\": the narrative-like summary of the DPA's investigation which names the facts and evidence recovered, etc.\n",
    "- I think it makes sense to define the indicators based on the field we expect to see them in, ie)\n",
    "    - \"failed_reqmt\" will be based on the \"summary of allegation\" info, not the findings.\n",
    "    - but is that fair? are there examples of this only appearing the findings? should all the text be processed together?\n",
    "- allegations will be \"eligible\" for modeling if they are:\n",
    "    - not initiated by the DPA (or OCC)\n",
    "    - not withdrawn or referred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ee220-e470-412f-9e53-5cec84059337",
   "metadata": {},
   "source": [
    "# TODO before getting started\n",
    "\n",
    "there are some improvements to the data processing that need to be made to support modeling:\n",
    "- [ ] debugging how the continued allegations are identified and regrouped\n",
    "    - I just ignored the continued text because they get treated as separate allegations and we were focusing on the summary of allegations field anyways, but if we're going to use the findings of fact then this needs to be fixed so those longer sections are processed as one.\n",
    "- [ ] improve the sustained label (the \"findings\" yaml file might be broken)\n",
    "    - [ ] does anything need to happen to make sure policy and training failures are counted as positive cases?\n",
    "- [ ] think about grouping the summary/findings sections to generate one indicator or if there's a good reason to treat them separately / make separate indicators\n",
    "    - I think there may be some examples of the DPA concluding something different than what was necessarily alleged in the complaint? but I don't know how common that is or if that's really fair given that the summary of allegations is already the DPA's interpretation of what was allegedly done wrong based on the complaint\n",
    "- [ ] does it make sense to do some feature importance analysis with the round3 classifier to trim the list of initial candidates? or should it be a fresh round of indicators with feature importance after new modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a797cf-784c-485b-b820-4a4e7908cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b15af26-4609-4e7a-a700-962c22c6faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4dec1c9-23ad-40a8-980f-153561e4c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "raw = pd.read_parquet(\"../../export/output/complaints.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d97ab0-4f1a-47db-9ee7-609167a73c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
